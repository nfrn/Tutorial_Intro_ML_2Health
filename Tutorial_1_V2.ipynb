{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMfsLj58ponl"
   },
   "source": [
    "**Interesting WebSites for Deep Learnig**\n",
    "\n",
    "*   http://scs.ryerson.ca/~aharley/vis/conv/flat.html\n",
    "*   https://playground.tensorflow.org\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jk4rI_7iHNZ2"
   },
   "outputs": [],
   "source": [
    "!pip install keras_tqdm\n",
    "!pip install matplotlib==3.1.0\n",
    "!pip install shap\n",
    "!pip install lime\n",
    "!pip install eli5\n",
    "!pip install seaborn\n",
    "!pip install sklearn\n",
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get -y install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ypoA2hfRTGbH"
   },
   "source": [
    "### **Breast Cancer Wisconsin (Diagnostic) Data Set**\n",
    "Processing data from:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/\n",
    "\n",
    "We read in the data and do some basic cleanup for missing values. For the description of the fields, see :\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names\n",
    "\n",
    "In summary:\n",
    "```\n",
    " Sample code number          : Id number (not used and thus dropped)\n",
    " Clump Thickness             : 1–10\n",
    " Uniformity of Cell Size     : 1–10\n",
    " Uniformity of Cell Shape    : 1–10\n",
    " Marginal Adhesion           : 1–10\n",
    " Single Epithelial Cell Size : 1–10\n",
    " Bare Nuclei                 : 1–10\n",
    " Bland Chromatin             : 1–10\n",
    " Normal Nucleoli             : 1–10\n",
    " Mitoses                     : 1–10\n",
    " Class                       : 2 for benign, 4 for malignant\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "px-Xiuafg24y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "pd.set_option(\"max_rows\", None)\n",
    "\n",
    "data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\", header=None)\n",
    "data = data.rename(columns={1: \"Clump Thickness\", 2: \"Uniformity of Cell Size\", 3: \"Uniformity of Cell Shape\",\n",
    "                   4: \"Clump Marginal Adhesion\",5: \"Single Epithelial Cell Size\",6: \"Bare Nuclei\",\n",
    "                   7: \"Bland Chromatin\",8: \"Normal Nucleoli\",9: \"Mitoses\",10: \"Class\"})\n",
    "data = data.drop(data.columns[0], axis=1)\n",
    "display(data)\n",
    "\n",
    "#Importante, olhar os dados ( algo estranho na linha 617?) (o valor da Class faz sentido?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rm3sAtn-vNzI"
   },
   "source": [
    "###**Data Cleaning and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9batnYVgnT_g"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "# Notice that in column 6 there are some missing values.\n",
    "display(df.loc[df[\"Bare Nuclei\"] == \"?\"].head(5))\n",
    "\n",
    "# We calculate the mean of that feature.\n",
    "df_6_without_missing_values = df[\"Bare Nuclei\"].loc[df[\"Bare Nuclei\"] != \"?\"]\n",
    "\n",
    "mean = df_6_without_missing_values.astype(int).mean()\n",
    "print(\"Mean value: \" + str(mean))\n",
    "\n",
    "median = df_6_without_missing_values.astype(int).median()\n",
    "print(\"Median value: \" + str(median))\n",
    "\n",
    "# Usar a media ou a mediana???\n",
    "\n",
    "# Replace missing values with mean value\n",
    "df[\"Bare Nuclei\"] = df[\"Bare Nuclei\"].replace(\"?\", mean)\n",
    "df[\"Bare Nuclei\"] = df[\"Bare Nuclei\"].astype(int)\n",
    "\n",
    "# Re-arranging labels 2 -> 0 and 4 -> 1\n",
    "df[\"Class\"] = df[\"Class\"].replace(2,0).replace(4,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTw9dMYnvGTE"
   },
   "source": [
    "###**Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQEuEVjuszOX"
   },
   "outputs": [],
   "source": [
    "#names = [ \"ID\", \"Clump thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\", \"Marginal Adhesion\", \"Single Epithelial Cell Size\", \"Bare Nuclei\", \"Bland Chromatin\", \"Normal Nucleoli\", \"Mitoses\", \"Class\" ]\n",
    "#df.columns = names[1:]\n",
    "hists = df.hist(bins=20, figsize=(15,20))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(df.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ByRXKjSAtS4x"
   },
   "outputs": [],
   "source": [
    "# Seaborn visualization library\n",
    "import seaborn as sns\n",
    "# Create the default pairplot\n",
    "sns.pairplot(df, hue = 'Class', diag_kind = 'kde',\n",
    "             plot_kws = {'alpha': 0.6, 's': 80, 'edgecolor': 'k'},\n",
    "             height = 4)\n",
    "\n",
    "\n",
    "# The diagonal diagrams describe\n",
    "# The other diagrams describe the relationship (or lack thereof) between two variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MEcNyj9UUU7"
   },
   "outputs": [],
   "source": [
    "# Using information from all columns (0-9) to predict target (column 10)\n",
    "X = df.iloc[:, :9]\n",
    "Y = df.iloc[:, 9]\n",
    "\n",
    "# Splitting between traning and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Checking the shapes to get an understanding of the problem\n",
    "print( X_train.shape, X_test.shape )\n",
    "print( Y_train.shape, Y_test.shape )\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hicj-8UXrO28"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier()\n",
    "dtree.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vII2YhZrWw2"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "Y_pred = dtree.predict(X_test)\n",
    "Y_pred = [ 1 if y>=0.5 else 0 for y in Y_pred]\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [\"Benign\", \"Malign\"],\n",
    "                  columns = [\"Benign\", \"Malign\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})\n",
    "plt.show()\n",
    "\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RRNEwuWXssDB"
   },
   "outputs": [],
   "source": [
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(dtree, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJGtogBYtHtc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J_TEA1Yj7Q9z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Feature importance dataframe\n",
    "imp_df = pd.DataFrame({'feature': [\"Clump Thickness\",\"Uniformity of Cell Size \",\"Uniformity of Cell Shape\", \"Marginal Adhesion\", \"Single Epithelial Cell Size\", \"Bare Nucleoli\", \"Bland Chromatin\",\" Normal Nucleoli\", \"Mitoses\"],\n",
    "                       'importance': dtree.feature_importances_})\n",
    " \n",
    "# Reorder by importance\n",
    "ordered_df = imp_df.sort_values(by='importance')\n",
    "imp_range=range(1,len(imp_df.index)+1)\n",
    " \n",
    "## Barplot with confidence intervals\n",
    "height = ordered_df['importance']\n",
    "bars = ordered_df['feature']\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "\n",
    "# Create horizontal bars\n",
    "plt.barh(y_pos, height)\n",
    " \n",
    "# Create names on the y-axis\n",
    "plt.yticks(y_pos, bars)\n",
    "\n",
    "plt.xlabel(\"Reduction in tree impurity in decision tree\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# Show graphic\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNx3T0yW32ag"
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Feature importance based on TRAINING set\n",
    "#eli5 provides a way to compute feature importances for any black-box estimator by measuring how score decreases when a feature is not available\n",
    "perm_test = PermutationImportance(dtree, scoring=make_scorer(accuracy_score),\n",
    "                                   n_iter=50, cv=\"prefit\")\n",
    "\n",
    "# fit and see the permuation importances\n",
    "perm_test.fit(X_train, Y_train)\n",
    "\n",
    "imp_df = eli5.explain_weights_df(perm_test)\n",
    "label_df = pd.DataFrame({'feature': [ \"x\" + str(i) for i in range(9)], 'feature_name': [\"Clump Thickness\",\"Uniformity of Cell Size \",\"Uniformity of Cell Shape\", \"Marginal Adhesion\", \"Single Epithelial Cell Size\", \"Bare Nucleoli\", \"Bland Chromatin\",\" Normal Nucleoli\", \"Mitoses\"]})\n",
    "imp_df = pd.merge(label_df, imp_df, on='feature', how='inner', validate=\"one_to_one\")\n",
    " \n",
    "# Reorder by importance\n",
    "ordered_df = imp_df.sort_values(by='weight')\n",
    "imp_range=range(1,len(imp_df.index)+1)\n",
    " \n",
    "\n",
    "## Barplot with confidence intervals\n",
    "\n",
    "height = ordered_df['weight']\n",
    "bars = ordered_df['feature_name']\n",
    "ci = 1.96 * ordered_df['std']\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "# Create horizontal bars\n",
    "plt.barh(y_pos, height, xerr=ci)\n",
    " \n",
    "# Create names on the y-axis\n",
    "plt.yticks(y_pos, bars)\n",
    "\n",
    "plt.xlabel(\"Permutation feature importance training set (decrease in accuracy)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAHeTgo057M5"
   },
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_explain = X_test\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(training_data=X_train,\n",
    "                                                   feature_names=[\"Clump Thickness\",\"Uniformity of Cell Size \",\"Uniformity of Cell Shape\", \"Marginal Adhesion\", \"Single Epithelial Cell Size\", \"Bare Nucleoli\", \"Bland Chromatin\",\" Normal Nucleoli\", \"Mitoses\"],\n",
    "                                                   discretize_continuous=True,\n",
    "                                                   class_names=[\"benign\", \"malign\"],\n",
    "                                                   mode=\"classification\",\n",
    "                                                   verbose=True)\n",
    "\n",
    "#Explaining first subject in test set using all 30 features\n",
    "exp = explainer.explain_instance(X_explain[21,:], dtree.predict_proba, \n",
    "                                 num_features=10)\n",
    "#Plot local explanation\n",
    "plt = exp.as_pyplot_figure()\n",
    "#plt.tight_layout()\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWn1_cKhw9lJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=(9), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, Y_train,batch_size=16,validation_split=0.2, epochs=30,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtJwonc4200T"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "Y_pred = model.predict(X_test,verbose=0)\n",
    "Y_pred = [ 1 if y>=0.5 else 0 for y in Y_pred]\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [\"Benign\", \"Malign\"],\n",
    "                  columns = [\"Benign\", \"Malign\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})\n",
    "plt.show()\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TjThjHdttvEH"
   },
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def predict(qc):\n",
    "    global model\n",
    "    prediction_Class_1 = model.predict_proba(qc) \n",
    "    x = np.zeros((prediction_Class_1.shape[0], 1))\n",
    "    probability = (x + 1) - prediction_Class_1\n",
    "    final = np.append(probability,prediction_Class_1, axis=1)\n",
    "    return final\n",
    "\n",
    "X_explain = X_test\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(training_data=X_train,\n",
    "                                                   feature_names=[\"Clump Thickness\",\"Uniformity of Cell Size \",\"Uniformity of Cell Shape\", \"Marginal Adhesion\", \"Single Epithelial Cell Size\", \"Bare Nucleoli\", \"Bland Chromatin\",\" Normal Nucleoli\", \"Mitoses\"],\n",
    "                                                   discretize_continuous=True,\n",
    "                                                   class_names=[\"benign\", \"malign\"],\n",
    "                                                   mode=\"classification\",\n",
    "                                                   verbose=True)\n",
    "print(np.array([X_test[0,:]]).shape)\n",
    "print(model.predict_proba(np.array([X_test[0,:]])))\n",
    "\n",
    "#Explaining first subject in test set using all 30 features\n",
    "exp = explainer.explain_instance(X_test[21,:], predict,num_features=10)\n",
    "#Plot local explanation\n",
    "plt = exp.as_pyplot_figure()\n",
    "#plt.tight_layout()\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Tutorial_1.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py37_tensorflow",
   "language": "python",
   "name": "conda-env-py37_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
